{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "#import keras\n",
    "from neuroner import neuromodel\n",
    "from shutil import copyfile, copy\n",
    "import random\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions charged with formatting the data set in the original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_brat_eHealth_format(path, file):\n",
    "    temp = pd.read_csv(path+file, sep='\\t', index_col=0, names=['label', 'txt'])\n",
    "    _temp = temp.label.str.split(expand=True, n=1)\n",
    "    temp['label'] = _temp[0]\n",
    "    temp['spans'] = _temp[1]\n",
    "    if temp.index.str.contains('T', regex=False).any(): temp.index = [i[1:] for i in temp.index]\n",
    "        \n",
    "    offset_to_change = temp.loc[temp.txt.str.split().str.len() > 1]\n",
    "    offset_to_change.txt = offset_to_change.txt.str.split()\n",
    "    offset_to_change.spans = offset_to_change.spans.str.split()\n",
    "    offset_to_change['relative_spans'] = [[len(elem) for elem in row] for row in offset_to_change.txt]\n",
    "    \n",
    "    for i in range(len(offset_to_change)):\n",
    "        current = int(offset_to_change.spans[i][0])\n",
    "        end = int(offset_to_change.spans[i][-1])\n",
    "        relative_spans = offset_to_change.relative_spans[i]\n",
    "        new_spans = []\n",
    "        for span in relative_spans:\n",
    "            new_spans.extend((str(current), str(current+span)+';'))\n",
    "            current = current+span+1\n",
    "        if int(new_spans[-1][:-1])!=end: print (\"diferentes tokens sin separar por espacio en: \", offset_to_change.index[i], new_spans[-1][:-1], end)\n",
    "        #print (' '.join(new_spans)[:-1].replace('; ', ';'))\n",
    "        temp.spans[temp.index == offset_to_change.index[i]] = ' '.join(new_spans)[:-1].replace('; ', ';')\n",
    "    print (temp[['spans', 'label', 'txt']])\n",
    "    temp[['spans', 'label', 'txt']].to_csv(path+file, sep='\\t', header=False)\n",
    "\n",
    "def paths_brat_eHealth_format(paths):    \n",
    "    for path in paths:\n",
    "        for f in os.listdir(path):\n",
    "            if os.path.isfile(os.path.join(path, f)) and f.endswith('.ann'):\n",
    "                to_brat_eHealth_format(path, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path of the model to be used to predict must be indicated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./output/(path on which the model to be evaluated was stored)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pretrained model \n",
    "All parameters are taken from the file \"parameters.ini\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_model': 0, 'use_pretrained_model': 1, 'pretrained_model_folder': './models/run2/', 'output_scores': 0, 'dataset_text_folder': './data/', 'main_evaluation_mode': 'token', 'output_folder': './output', 'use_character_lstm': 1, 'character_embedding_dimension': 25, 'character_lstm_hidden_state_dimension': 25, 'token_pretrained_embedding_filepath': '', 'token_embedding_dimension': 200, 'token_lstm_hidden_state_dimension': 200, 'use_crf': 1, 'patience': 100, 'maximum_number_of_epochs': 100, 'optimizer': 'sgd', 'learning_rate': 0.001, 'gradient_clipping_value': 0.0, 'dropout_rate': 0.5, 'number_of_cpu_threads': 8, 'number_of_gpus': 1, 'experiment_name': 'test', 'tagging_format': 'bioes', 'tokenizer': 'spacy', 'spacylanguage': 'es', 'remap_unknown_tokens_to_unk': 1, 'load_only_pretrained_token_embeddings': 0, 'check_for_lowercase': 1, 'check_for_digits_replaced_with_zeros': 1, 'freeze_token_embeddings': 0, 'debug': 0, 'verbose': 0, 'plot_format': 'png', 'reload_character_embeddings': 1, 'reload_character_lstm': 1, 'reload_token_embeddings': 1, 'reload_token_lstm': 1, 'reload_feedforward': 1, 'reload_crf': 1, 'load_all_pretrained_token_embeddings': False, 'parameters_filepath': './parameters.ini'}\n",
      "Checking compatibility between CONLL and BRAT for train_spacy set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking compatibility between CONLL and BRAT for valid_spacy set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "Checking compatibility between CONLL and BRAT for deploy_spacy set ... Done.\n",
      "Checking validity of CONLL BIOES format... Done.\n",
      "WARNING: train and valid set exist in the specified dataset folder, \n",
      "                but train_model is set to FALSE: ./data/\n",
      "Load dataset... done (0.65 seconds)\n",
      "INFO:tensorflow:Restoring parameters from ./models/run2/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "nn = neuromodel.NeuroNER(train_model=False, use_pretrained_model=True, \n",
    "                         pretrained_model_folder=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch 0\n",
      "Training completed in 0.00 seconds\n",
      "Evaluate model on the train set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action     0.8505    0.8618    0.8561       977\n",
      "     Concept     0.9438    0.9262    0.9349      2899\n",
      "   Predicate     0.7529    0.5773    0.6535       343\n",
      "   Reference     0.9048    0.5802    0.7070       131\n",
      "\n",
      "   micro avg     0.9089    0.8738    0.8910      4350\n",
      "   macro avg     0.8630    0.7364    0.7879      4350\n",
      "weighted avg     0.9066    0.8738    0.8881      4350\n",
      "\n",
      "Evaluate model on the valid set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action     0.7531    0.7262    0.7394       168\n",
      "     Concept     0.8660    0.9085    0.8867       448\n",
      "   Predicate     0.6667    0.4783    0.5570        46\n",
      "   Reference     0.9091    0.4167    0.5714        24\n",
      "\n",
      "   micro avg     0.8299    0.8178    0.8238       686\n",
      "   macro avg     0.7987    0.6324    0.6886       686\n",
      "weighted avg     0.8265    0.8178    0.8175       686\n",
      "\n",
      "Predict labels for the deploy set\n",
      "Generating plots for the train set\n",
      "Generating plots for the valid set\n",
      "/usr/local/lib/python3.6/dist-packages/neuroner\n",
      "shell_command: perl /usr/local/lib/python3.6/dist-packages/neuroner/conlleval < ./output/_2019-06-06_14-53-19-53539/000_train.txt > ./output/_2019-06-06_14-53-19-53539/000_train.txt_conll_evaluation.txt\n",
      "/usr/local/lib/python3.6/dist-packages/neuroner\n",
      "shell_command: perl /usr/local/lib/python3.6/dist-packages/neuroner/conlleval < ./output/_2019-06-06_14-53-19-53539/000_valid.txt > ./output/_2019-06-06_14-53-19-53539/000_valid.txt_conll_evaluation.txt\n",
      "Formatting 000_train set from CONLL to BRAT... Done.\n",
      "Formatting 000_valid set from CONLL to BRAT... Done.\n",
      "Formatting 000_deploy set from CONLL to BRAT... Done.\n",
      "Finishing the experiment\n"
     ]
    }
   ],
   "source": [
    "nn.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_process = \"./output/\"+model+\"/000_deploy.txt\" # the path of the output file on which the entities are predicted by NeuroNER model\n",
    "original_brat = \"./data/deploy/\" # the path where we locate the test dataset\n",
    "brat_output = \"./data/deploy/\" # the path on which the processed file is going to be saved on brat format\n",
    "\n",
    "neuromodel.conll_to_brat.conll_to_brat(path_to_process, path_to_process, original_brat, brat_output, overwrite=True)\n",
    "paths_brat_eHealth_format([brat_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the execution has finished, the final output should be placed in the folder indicated by \"brat_output\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
